{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfec002",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare data</a></span></li><li><span><a href=\"#Compare-methods\" data-toc-modified-id=\"Compare-methods-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compare methods</a></span></li><li><span><a href=\"#Analyze-clustering\" data-toc-modified-id=\"Analyze-clustering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyze clustering</a></span></li><li><span><a href=\"#Is-our-clustering-stable-across-waves?\" data-toc-modified-id=\"Is-our-clustering-stable-across-waves?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Is our clustering stable across waves?</a></span></li><li><span><a href=\"#Soft-Clustering-(Fuzzy-K-means)\" data-toc-modified-id=\"Soft-Clustering-(Fuzzy-K-means)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Soft Clustering (Fuzzy K-means)</a></span></li><li><span><a href=\"#consistency-regarding-only-continuous-(repeated-in-different-waves)-questions\" data-toc-modified-id=\"consistency-regarding-only-continuous-(repeated-in-different-waves)-questions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>consistency regarding only continuous (repeated in different waves) questions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deviations-for-the-same-opinion-questions-across-the-waves\" data-toc-modified-id=\"Deviations-for-the-same-opinion-questions-across-the-waves-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Deviations for the same opinion questions across the waves</a></span></li><li><span><a href=\"#Checking-consistency-of-confidently-clustered-samples-among-the-same-questions-in-different-waves\" data-toc-modified-id=\"Checking-consistency-of-confidently-clustered-samples-among-the-same-questions-in-different-waves-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Checking consistency of confidently clustered samples among the same questions in different waves</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24c2a0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "hide_input": false,
    "tags": []
   },
   "source": [
    "# Clustering\n",
    "\n",
    "Initially we looked at correlation between features and noticed that the largest ones (in terms of magnitude) appeared amongst the **opinion** question. So the question arose\n",
    "> Can we group participants into two classes based on their political opinion?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9563d2",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d01c6c0c6ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m from utils.utils_clustering import (\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mcompare_4_clusters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mplot_left_right\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "sys.path.insert(0, \"../utils/\")\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import seaborn as sns\n",
    "from dictionaries_rename import (\n",
    "    get_binary_names,\n",
    "    get_dummies_names,\n",
    "    get_ordinal_names,\n",
    "    opinion_questions,\n",
    ")\n",
    "from ipywidgets import interact\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import cluster\n",
    "from sklearn.decomposition import PCA\n",
    "from utils.utils_clustering import (\n",
    "    compare_4_clusters,\n",
    "    delete_unique,\n",
    "    individual_check,\n",
    "    plot_clusters,\n",
    "    plot_deviations,\n",
    "    plot_left_right,\n",
    "    plot_mean_label,\n",
    "    plot_party_choice,\n",
    "    plot_stability,\n",
    "    real_or_nan,\n",
    "    save_fig,\n",
    "    show_features,\n",
    "    sort_by_absolute_val,\n",
    "    store_results,\n",
    "    waves_to_switch,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112a975-27af-4e74-8549-59a96c219bc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba841de",
   "metadata": {},
   "source": [
    "- Input: `data_online_political_w{wave}.csv`\n",
    "- Output for each wave: \n",
    "    * `df_opinions`  without wrong check questions, no shows removed, feature names prettified, immigration relared questions tagges, \n",
    "    * `left_right` placement, obtained either from *LEFT-RIGHT SELF-PLACEMENT* or *PREFERRED COALITION: OEVP-FPOE* (if no self-placement is available);\n",
    "    * `party_choice` (based on *PARTY CHOICE: PROSPECTIVE*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91f5fd-ece9-46ef-85fb-e79860224087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run Prepare_clustering_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d22e2",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "The questions from the list below were asked only once, but in different waves, therefore makes no sense to use them when it is splitted into e.g. 3 columns in 3 waves with random samples.\n",
    "However when I removed them, the clustering assignment stability became a waste as these questions were the most important ones (even when too namy NaNs are replaced by mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd8e85-c91d-4486-88c6-14dfc749a489",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf9dde-81b2-41bd-977d-353cd422af0a",
   "metadata": {},
   "source": [
    "In this section we investigated different clustering methods performance (with Kmeans being the most efficient one) and tried to obtain the most optimal number of clusters (which eventually is 2). For more details, see [Compare_clustering_methods notebook](./Compare_clustering_methods.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7725510",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Analyze clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f794ca",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We use the Kmeans algorithm since it performed the best in the previous evaluations. This method not only compute a clustering but also a *centroid* for every cluster and the distance of every point to those centers. Every point will simply be assigned to the centroid to which it has this smallest distance. If the distance of a point to its centroid is much smaller than its distance to the other centroid we tend to be more confident in it's assignment. So we compute quotient of the distances to the two centroids. Next we compute the median of all quotients of all points in a class and call the closest half *close* and the half that is further away than this median *far*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74ee90",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_closeness_label(df, n):\n",
    "    \"\"\"Given a clustering in a dataframe decide for every point whether it is\n",
    "    close of far from its centroid. This should reflect the confidence with\n",
    "    which the point is assinged to its cluster.\"\"\"\n",
    "\n",
    "    df[\"Distance\"] = np.NaN\n",
    "    for label in range(n):\n",
    "        df_label = df.loc[df.Label == label]\n",
    "        threshold = df_label[\"quotient\"].quantile(0.8)\n",
    "\n",
    "        df.loc[df.Label == label, \"Distance\"] = df_label[\"quotient\"].apply(\n",
    "            lambda x: 0 if x > threshold else 1\n",
    "        )  # close => 1, far => 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_clusters(X, n):\n",
    "    \"\"\"Clusters dataset into n groups and additionally asigns every point a label\n",
    "    depending on whether it is 'close' and 'far' from centroid,\n",
    "    hoping that close ones are clustered more confidently\n",
    "    \"\"\"\n",
    "\n",
    "    kmeans = cluster.KMeans(n_clusters=n, random_state=42).fit(X)\n",
    "    X_dist = kmeans.transform(X)\n",
    "    quotient = X_dist.min(axis=1) / X_dist.max(axis=1)\n",
    "    df_cluster = pd.DataFrame(quotient, columns=[\"quotient\"])\n",
    "    df_cluster.index = X.index\n",
    "    df_cluster[\"Label\"] = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    df = add_closeness_label(df_cluster, n)\n",
    "\n",
    "    return df, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c1f6d6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "source": [
    "For illustration purposes we also compute a principal component analysis (PCA) of all the opinion question which allows us to visualize the obtained clustering and centroids in a lower dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6253c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_dims(df, centroids):\n",
    "    \"\"\"Compute PCA of opinion questions and transform data and centroids into new\n",
    "    coordinate system for plotting\"\"\"\n",
    "\n",
    "    # 2 components for 2D visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(df)\n",
    "\n",
    "    explained_variance = pd.DataFrame(pca.explained_variance_ratio_).T\n",
    "\n",
    "    # obtain data transformed into 2 dimensions for illustration purposes\n",
    "    df_pc = pd.DataFrame(pca.transform(df))\n",
    "    df_pc.columns = [\"1st component\", \"2nd component\"]\n",
    "    df_pc.index = df.index\n",
    "\n",
    "    centroids_pc = pca.transform(centroids)\n",
    "\n",
    "    # get the most important features, representing axes\n",
    "    eigenvectors = pd.DataFrame(\n",
    "        pca.components_.T, index=df.columns, columns=[\"Eigenvector 1\", \"Eigenvector 2\"]\n",
    "    )\n",
    "\n",
    "    return df_pc, centroids_pc, explained_variance, eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47799a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Additionally, for every question we compute the average strength of agreement for people of the same cluster and compare these values between the groups. We only list here the subset of question with the largest difference in agreement between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2ec46",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_differences(df, wave):\n",
    "    \"\"\"Computes for both classes the average agreement for the different questions\"\"\"\n",
    "\n",
    "    df_cluster_means = df.groupby([\"Label\"]).mean().T\n",
    "    differences = (df_cluster_means[1] - df_cluster_means[0]).sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    "    strongest_differences = pd.DataFrame(differences)\n",
    "    strongest_differences.columns = [\"Difference\"]\n",
    "    strongest_differences = strongest_differences[\n",
    "        ~strongest_differences.index.duplicated()\n",
    "    ]\n",
    "\n",
    "    strongest_differences = sort_by_absolute_val(strongest_differences, \"Difference\")\n",
    "    wave_to_switch = waves_to_switch(strongest_differences, wave)\n",
    "\n",
    "    return strongest_differences, wave_to_switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2841fc5-eb9d-4615-89e7-9663df30506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(df, explained_variance, eigenvectors, strongest_differences, wave):\n",
    "    \"\"\"store the results in the nested dict\"\"\"\n",
    "    clustering_info = {}\n",
    "    clustering_info[f\"Table 1. Explained variance, wave {wave}\"] = explained_variance\n",
    "    clustering_info[\n",
    "        f\"Table 2. Important features (PCA), 1 component, wave {wave}\"\n",
    "    ] = sort_by_absolute_val(eigenvectors, \"Eigenvector 1\")[\"Eigenvector 1\"].to_frame()\n",
    "    clustering_info[\n",
    "        f\"Table 3. Important features (PCA), 2 component, wave {wave}\"\n",
    "    ] = sort_by_absolute_val(eigenvectors, \"Eigenvector 2\")[\"Eigenvector 2\"].to_frame()\n",
    "    clustering_info[\n",
    "        f\"Table 4. The most important factors regarding differences between clusters (1 minus 0), wave {wave}\"\n",
    "    ] = strongest_differences\n",
    "    return clustering_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51a3a3-4bd2-4d47-91eb-9a87c198fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_each_wave(left_right, party_choice, wave, df, n):\n",
    "    \"\"\"Perform clustering of given wave and compute important quantities through PCA and other methods.\n",
    "    In other words, this function puts others together, making cluster analysis, dim reduction\n",
    "    and plotting\n",
    "    \"\"\"\n",
    "    df_cluster, centroids = compute_clusters(df, n)\n",
    "\n",
    "    # compute coordinates with respect to new basis\n",
    "    df_pc, centroids_pc, explained_variance, eigenvectors = reduce_dims(df, centroids)\n",
    "\n",
    "    # plotting\n",
    "    df_plot = pd.concat([df_pc, df_cluster.Label, df_cluster.Distance], axis=1)\n",
    "    plot_left_right(left_right, df_plot, centroids_pc, wave)\n",
    "\n",
    "    # the question about party choice was asked only in waves 1-4\n",
    "    if wave in {\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "    }:\n",
    "        plot_party_choice(party_choice, df_plot, centroids_pc, wave)\n",
    "\n",
    "    # add cluster label column\n",
    "    df = pd.concat([df, df_cluster[\"Label\"]], axis=1)\n",
    "\n",
    "    # different functions to obtain the most important factors for different numbers of clusters\n",
    "    if n == 2:\n",
    "        strongest_differences, wave_to_switch = cluster_differences(df, wave)\n",
    "    else:\n",
    "        strongest_differences = compare_4_clusters(df, wave)\n",
    "        wave_to_switch = []\n",
    "    cluster_w = df_cluster.drop(columns=\"quotient\")\n",
    "    cluster_w = cluster_w.rename(\n",
    "        {\"Label\": f\"Label w{wave}\", \"Distance\": f\"Close to centroid w{wave}\"}, axis=1\n",
    "    )\n",
    "    clustering_info = store_results(\n",
    "        df, explained_variance, eigenvectors, strongest_differences, wave\n",
    "    )\n",
    "    all_waves_clustering_info = {}\n",
    "    all_waves_clustering_info[wave] = clustering_info\n",
    "    return cluster_w, all_waves_clustering_info, wave_to_switch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f036f94-feb3-4d5a-9d7a-b1071355909a",
   "metadata": {},
   "source": [
    "### Execution 2 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad38aa4-e2ee-44ff-95de-44ace6eb70bf",
   "metadata": {},
   "source": [
    "Execute `clustering_each_wave` for 2 clusters and every wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887ed44-e75e-4e3c-a1d0-3dbd228e46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered = pd.DataFrame()\n",
    "all_waves_clustering_info_2 = {}\n",
    "list_to_switch = []\n",
    "for wave in waves:\n",
    "    (\n",
    "        df_clustered_w,\n",
    "        all_waves_clustering_info_2[wave],\n",
    "        wave_to_switch,\n",
    "    ) = clustering_each_wave(left_right, party_choice, wave, df_opinion[wave], 2)\n",
    "    list_to_switch.append(wave_to_switch)\n",
    "    df_clustered = pd.concat([df_clustered, df_clustered_w], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f8b48-d3d2-492a-bb10-d7bf3558044f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Wave 1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "33e1a3dc-1c99-405f-ac82-27230c6d55bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, values in all_waves_clustering_info_2[\"1\"].items():\n",
    "    for key_, values_ in values.items():\n",
    "        display(values_[:5].style.set_caption(key_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e837c4-95e3-42c0-b7f7-9e4e5d246dc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "The table 2 with 1st eigenvector clearly shows, that the most of division between clusters can be explained solely by immigtration related questions (which are tagged with *im*). Same can be observed on the plot (Left-right self-placement) above: separation is almost vertical (1st component is represented by x-axis). We would like to remind, that opinion questions are coded in the following way:\n",
    "* 1 - completely agree \n",
    "* 2 - somewhat agree\n",
    "* 3 - partly agree/disagree/don't know\n",
    "* 4 - somewhat disagree \n",
    "* 5 - completely disagree\n",
    "\n",
    "Therefore, larger values of eigenvector coefficients mean more disagreement. Moving towards the right side of x-axis on this plot means more pro-immigrant position.\n",
    "In other words, cluster 0 is more immigrant-friendly, than cluster 1. \n",
    "\n",
    "That corresponds the results from table 4: there we substract mean opinion values of cluster 0 from cluster 1. On top of that we see the match with colors of self left-right placement, when cluster 0 is colored mostly with red and cluster 1 is predominantly blue. There are many grey dots, which can be explained by the fact, that most of the people prefer option closer to the middle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c53fa-a958-4e25-9266-84cb0e0d2ddf",
   "metadata": {},
   "source": [
    "For illustration purposes we leave wave 1 results permamently visible. For the access to the other waves please run the notebook and use the widget below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6a2cd-ef97-4316-8b36-9ebe2c89e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the tables as csv\n",
    "for wave in waves:\n",
    "    for component, table in zip([1, 2], [2, 3]):\n",
    "        round(\n",
    "            all_waves_clustering_info_2[wave][wave][\n",
    "                f\"Table {table}. Important features (PCA), {component} component, wave {wave}\"\n",
    "            ][:5],\n",
    "            3,\n",
    "        ).to_csv(f\"../../../output/component{component}_wave{wave}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132b513-6347-48c4-b31d-91aedeebd4d6",
   "metadata": {},
   "source": [
    "### Execution 4 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b721175-1462-4e33-baa8-22665ee6bf6c",
   "metadata": {},
   "source": [
    "Execute `clustering_each_wave` for 4 clusters and every wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "4efb21e9-a4a9-4ba2-a6ad-1bb116cf26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# line 1 prevents 4 clusters plotting (use the widget below)\n",
    "\n",
    "all_waves_clustering_info_4 = {}\n",
    "for wave in waves:\n",
    "    (\n",
    "        df_clustered_w,\n",
    "        all_waves_clustering_info_4[wave],\n",
    "        wave_to_switch,\n",
    "    ) = clustering_each_wave(left_right, party_choice, wave, df_opinion[wave], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000fe71-788e-4135-a553-2c72c922dfc0",
   "metadata": {},
   "source": [
    "### Results (all waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d5c68",
   "metadata": {},
   "source": [
    "Here it is possible to input values such as wave and number of clusters and get the result without scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac31b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],

   "source": [
    "@interact\n",
    "def interactive_results(wave=waves, clusters=[2, 4]):\n",
    "    show_features(\n",
    "        wave, clusters, all_waves_clustering_info_2, all_waves_clustering_info_4\n",
    "    )\n",
    "    plot_clusters(wave, clusters, left_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de98fb",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Is our clustering stable across waves?\n",
    "\n",
    "We start with the following premise:\n",
    "> Political opinions of people in general don't vary much in short periods of time.\n",
    "\n",
    "If this is indeed the case it makes sense to look at our clustering across different waves and check if participants are constantly assigned to the same cluster? It should be noted here that it's not so easy to define what we mean by \"same\" cluster as there are no external labels. However, by looking for example at the question with the biggest difference between the two clusters we can see a clear nationalist-liberal trend and can therefore manually give meaning to the two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf53312",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def switch_labels(list_to_switch, df):\n",
    "    \"\"\"switch labels 1 and 0 for clusters check cluster consistency\"\"\"\n",
    "    # drop None values, which mean, that no changes of labels needed\n",
    "    list_to_switch = [wave for wave in list_to_switch if wave is not None]\n",
    "    # make signs corresponding\n",
    "    for wave in list_to_switch:\n",
    "        df[f\"Label w{wave}\"] = abs(df[f\"Label w{wave}\"] - 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b81b4-4aa0-4574-b7f1-c5363eecc922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clustered = switch_labels(list_to_switch, df_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7e0e3",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "For each participant we then compute the `mean` of their respective labels across waves. If they have  been assigned the label $1$ in all waves in which they participated, then the mean is $1$. Analogously for label $0$. If the mean of the labels of a given participant is strictly between $0$ and $1$ this means that they have not been assigned the same group in all waves. The mean being close to $0$ or $1$ indicates that a person has been given the same label *most of the time*.\n",
    "\n",
    "Naturally, we assume that political opinions of people, no matter the topic, are not black or white, but located on a spectrum. People who are located somewhere in the middle might be assigned a different cluster in later waves even if their opinion did not change. For this reason we want to see if the assignment of clusters across waves becomes even more stable if we only consider people that are much closer to their centroid then they are to the other one. In some sense those people are clustered more confidently.\n",
    "\n",
    "On top of that we also want to see whether cluster assignment becomes more stable when we exclude wave 6 as there are no immigration related questions, which are usually the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8ca1e-60b2-44f4-980a-433d83bb38b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_close = df_clustered.copy()\n",
    "print(\"Rate of included participants (close to centroids):\")\n",
    "for wave in waves:\n",
    "    df_close = df_close.loc[df_close[f\"Close to centroid w{wave}\"] != 0]\n",
    "    included_rate = (\n",
    "        df_close.count(axis=0)[int(wave) * 2 - 1]\n",
    "        / df_clustered.count(axis=0)[int(wave) * 2 - 1]\n",
    "    )\n",
    "    print(f\"wave {wave}: \", np.int(included_rate * 100), \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307da3a0-f769-4777-8fea-6ac33a10bd5e",
   "metadata": {},
   "source": [
    "Considering only people which are close to centroids during all waves, we eventually leave only 44% of samples. So we also want to know the picture with all people, who were closely assigned at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9a9d0-9397-459e-a57e-9f41e0b9faa1",
   "metadata": {},
   "outputs": [],

   "source": [
    "%matplotlib inline\n",
    "@interact\n",
    "def interactive_stability(\n",
    "    include=[\"always closely located samples\", \"samples close at least once\"],\n",
    "    exclude_wave_6=True,\n",
    "):\n",
    "    plot_stability(include, exclude_wave_6, df_clustered, df_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc545a0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Evidently, most of the people are assigned to the same group all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728e581-cd98-4f45-b81e-57493d0df8f1",
   "metadata": {},
   "source": [
    "Not confident samples are those, whose probability to be assigned to any cluster is lower than threshold (e.g. 30% to cluster 0 and 30% to cluster 1 while threshold is 65%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183d0c0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## consistency regarding only continuous (repeated in different waves) questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d1116",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Deviations for the same opinion questions across the waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2480782",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_names = []\n",
    "for wave in waves:\n",
    "    list_wave = df_opinion[wave].columns\n",
    "    cols_names.extend(list_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c264cca",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_names = delete_unique(cols_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b4162",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merging all waves opinions into 1 df with all waves to check consisency among the same questions afterwards\n",
    "opinion_all_waves = pd.DataFrame([])\n",
    "for wave in waves:\n",
    "    opinion_all_waves = pd.concat([opinion_all_waves, df_opinion[wave]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e3013-5257-4fdf-a9e1-a98ec91fb059",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_deviations(df, cols_names):\n",
    "    \"\"\"creates dataframes for every question, containing only columns with that particular question\n",
    "    with number of cols equal to number of times question was asked among the waves, finds the difference between\n",
    "    max and min opinions\n",
    "\n",
    "    :input:\n",
    "    - merged df with all opinions for all the waves\n",
    "    - names of questions repeated aming different waves at least twice\n",
    "\n",
    "    :return:\n",
    "    - difference between max and min value of opinion\n",
    "\n",
    "    \"\"\"\n",
    "    deviations = pd.DataFrame([])\n",
    "    for question in cols_names:\n",
    "        df_ = df.filter(like=question, axis=1)\n",
    "        # some people answered the question only once, we do not want to include them\n",
    "        # as algorithm will consider them as never deviated, so they are marked as NaN\n",
    "        df_[\"Number of responces\"] = df_.count(axis=1)\n",
    "        df_ = df_.mask(df_[\"Number of responces\"] == 1)\n",
    "        df_.drop([\"Number of responces\"], axis=1, inplace=True)\n",
    "        df_ = df_.max(axis=1) - df_.min(axis=1)\n",
    "        deviations = pd.concat([deviations, df_], axis=1)\n",
    "    deviations.columns = cols_names\n",
    "    return deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fb124-9c77-4cff-ae67-a70b29a32508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opinion_deviations = find_deviations(opinion_all_waves, cols_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b5885-6bf4-44be-b224-fc9e3de70be2",
   "metadata": {},
   "source": [
    "Previously we observed peaks in terms of number of people who significantly changed their opinions for some questions. But when we checked these outliers it turned out, that this is caused by the fact that some questions were asked only once for each person, but during different waves. During preparation step we changed NaN into neutral option (2), which caused peaks for some questions. These questions need to be removed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "59335458-f3c7-421b-b755-c6c3602af5a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get df with initial features codes\n",
    "dict_ordinals = get_ordinal_names()\n",
    "dict_ordinals = pd.DataFrame(dict_ordinals.items(), columns=[\"key\", \"fname\"])\n",
    "dict_ordinals.index = dict_ordinals[\"fname\"]\n",
    "dict_ordinals.drop([\"fname\"], axis=1, inplace=True)\n",
    "dict_ordinals = dict_ordinals.T\n",
    "dict_ordinals.columns = dict_ordinals.columns.str.split(\"-w\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "7e45b272-2b81-4241-9ce2-d0abda24f44d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check how many NaN questions have, if rate >= 50%, then the question was asked only once, makes no sense to use it for stability check\n",
    "df_init = pd.read_csv(\"../../../data/raw/10017_da_en_v2_0.tab\", sep=\"\\t\")\n",
    "nan_list = []\n",
    "for question in cols_names:\n",
    "    if \"im\" in question:\n",
    "        question = question.split(\"im: \")[1]\n",
    "    codes = (dict_ordinals[question]).values.tolist()[0]\n",
    "    nan_rate = df_init[codes].isna().sum().sum() / (\n",
    "        df_init[codes].shape[0] * df_init[codes].shape[1]\n",
    "    )\n",
    "    nan_list.append(nan_rate)\n",
    "df_nan = pd.DataFrame([nan_list], columns=cols_names, index=[\"NaN rate\"]).T\n",
    "df_nan.sort_values(by=\"NaN rate\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "73190374-3c8b-4743-a5d6-4b976104f8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asked_once = df_nan[df_nan[\"NaN rate\"] >= 0.5]\n",
    "asked_once_cols = asked_once.index\n",
    "display(asked_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb18e23-ced4-4b03-bd94-9da66cf13876",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the above mentioned questions\n",
    "opinion_deviations.drop([asked_once.index][0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213989d-baab-478a-8c95-6a0a3b402e23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nans = opinion_deviations.isnull().sum().to_frame()\n",
    "# group deviations by its degrees for each question\n",
    "opinion_deviations = opinion_deviations.apply(pd.value_counts).T\n",
    "opinion_deviations = pd.concat([opinion_deviations, nans], axis=1)\n",
    "opinion_deviations.columns = [0, 1, 2, 3, 4, \"NaN\"]\n",
    "opinion_deviations.drop(\"NaN\", axis=1, inplace=True)\n",
    "opinion_deviations = opinion_deviations.sort_values(\n",
    "    [4, 3, 2], ascending=(True, True, True)\n",
    ").T\n",
    "# since the questions were not asked always and sometimes number of respondents is vastly different, deviations stats converted into petcentages\n",
    "opinion_deviations = (100.0 * opinion_deviations / opinion_deviations.sum()).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75ccca-0140-4e31-ad07-75bb6fee745b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_deviations(opinion_deviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2301e-7ec3-4f64-ab41-56c6eb1c88fd",
   "metadata": {},
   "source": [
    "The plot above shows that there are up to 10-12% of people, significantly changing their opinions about particular questons. This might explain the fact, that if we have rate of those, who never change their cluster assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37264032",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Labels heatmap across the waves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779c534",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In this plot we filter only people, which are always close to centroids (therefore only participants, which never drop were included) to individually check if they were confidently assigned to the same cluster or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdbda4",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "individual_check(df_clustered, waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4000cc8",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Cluster assignment is literally the same for them across the waves. Cluster 6 does not contain any immigration questions (causing the largest differences), therefore it is not possible to adequately compare it with others. However, if we delete immigration opinions to have the same base, that might change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this notebook to pdf but without the code\n",
    "#!jupyter nbconvert --to pdf --TemplateExporter.exclude_input=True --output-dir=output_pdf clustering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c8a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4e8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "282px",
    "left": "1154px",
    "top": "112.3px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
